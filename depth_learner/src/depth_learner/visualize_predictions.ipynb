{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from models.base_learner import LearnerResnet, LearnerEigen\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'ds': 'uvd',    \n",
    "    'use_eigen': False,\n",
    "    'rgb_dir': './data/uvd/test/09/Images/',\n",
    "    'depth_dir': './data/uvd/test/09/DepthSR/'\n",
    "}\n",
    "config_resnet = {\n",
    "    'checkpoint_file': './experiments/resnet50_0306/model-40',\n",
    "    'input_width': 304,\n",
    "    'input_height': 228,\n",
    "    'output_width': 304,\n",
    "    'output_height': 228,\n",
    "    'l2_reg_scale': 0.0\n",
    "}\n",
    "config_eigen = {\n",
    "    'checkpoint_file': './tests_uvd/eigen_0106/model-130',\n",
    "    'input_width': 304,\n",
    "    'input_height': 228,\n",
    "    'output_width': 74,\n",
    "    'output_height': 55,\n",
    "    'l2_reg_scale': 0.0\n",
    "}\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 7.0) # set default size of plots\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Define utilities & metrics\n",
    "#---------------------#\n",
    "def cvt2depth(img):\n",
    "    scaling = 40.0/255 #factor to convert intensity to m\n",
    "    return img.astype(float)*scaling\n",
    "def diff (pred, target):\n",
    "    return np.abs(pred-target)\n",
    "def calc_rmse(pred, target):\n",
    "    d = diff(cvt2depth(pred), cvt2depth(target))\n",
    "    return np.sqrt(np.mean(d**2))\n",
    "def calc_logrmse(pred, target):\n",
    "    pred = cvt2depth(np.clip(pred,1e-4,float('inf')))\n",
    "    target = cvt2depth(np.clip(target,1e-4,float('inf')))\n",
    "    log_d = diff(np.log(pred), np.log(target))\n",
    "    return np.sqrt(np.mean(log_d**2))\n",
    "def calc_rel(pred, target):\n",
    "    d = diff(cvt2depth(pred), cvt2depth(target))\n",
    "    target = cvt2depth(target)\n",
    "    return np.mean(d/target)\n",
    "def calc_simse(pred, target):\n",
    "    pred = cvt2depth(np.clip(pred,1e-4,float('inf')))\n",
    "    target = cvt2depth(np.clip(target,1e-4,float('inf')))\n",
    "    log_d = diff(np.log(pred), np.log(target))\n",
    "    return np.mean(log_d**2)-np.mean(log_d)**2\n",
    "def calc_d125(pred, target):\n",
    "    d_lower = cvt2depth(pred)/cvt2depth(target)\n",
    "    d_upper = cvt2depth(target)/cvt2depth(pred)\n",
    "    inlier = pred[np.logical_and(d_lower<1.25, d_upper<1.25)]\n",
    "    return float(inlier.size)/float(target.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if config['use_eigen']:\n",
    "    #---------------------#\n",
    "    # Restore Eigen model\n",
    "    #---------------------#\n",
    "    tf.reset_default_graph()\n",
    "    gEigen = tf.Graph()\n",
    "    with gEigen.as_default():\n",
    "        learnerEigen = LearnerEigen()\n",
    "        learnerEigen.setup_inference(config_eigen)\n",
    "        saverEigen = tf.train.Saver()\n",
    "        sessEigen = tf.Session()\n",
    "        saverEigen.restore(sessEigen, config_eigen['checkpoint_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Restore Resnet model\n",
    "#---------------------#\n",
    "tf.reset_default_graph()\n",
    "gResnet = tf.Graph()\n",
    "with gResnet.as_default():\n",
    "    learnerResnet = LearnerResnet()\n",
    "    learnerResnet.setup_inference(config_resnet)\n",
    "    \n",
    "    # Restore all found variables\n",
    "    reader = tf.train.NewCheckpointReader(config_resnet['checkpoint_file'])\n",
    "    checkpoint_shapes = reader.get_variable_to_shape_map()\n",
    "    checkpoint_names = set(checkpoint_shapes.keys())\n",
    "    model_names = set([v.name.split(':')[0] for v in tf.global_variables()])\n",
    "    found_names = model_names & checkpoint_names\n",
    "    found_vars = []\n",
    "    lost_vars = model_names - checkpoint_names\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        for name in found_names:\n",
    "            var = tf.get_variable(name)\n",
    "            found_vars.append(var)\n",
    "        print('Restored %d variables' % len(found_names))\n",
    "    saverResnet = tf.train.Saver(var_list=found_vars)\n",
    "    \n",
    "    sessResnet = tf.Session()\n",
    "    saverResnet.restore(sessResnet, config_resnet['checkpoint_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Plot UVD results \n",
    "# this function will plot 3 rows of images and depth predictions\n",
    "# 1st image: first_frame\n",
    "# 2nd image: first_frame+1*frame_spacing\n",
    "# 2nd image: first_frame+2*frame_spacing\n",
    "#---------------------#\n",
    "first_frame=100\n",
    "frame_spacing=500\n",
    "\n",
    "n_rows=3\n",
    "if config['use_eigen']:\n",
    "    n_cols=4\n",
    "else:\n",
    "    n_cols=3\n",
    "\n",
    "fig = plt.figure(figsize=(20,n_rows*4))\n",
    "fig_row=1\n",
    "# Only even img_numbers are allowed\n",
    "for img_nr in range(2, 2+n_rows*frame_spacing, frame_spacing):\n",
    "    filename_rgb = os.path.join(config['rgb_dir'], \"%04d\"%img_nr + ' 02.png')\n",
    "    filename_depth = os.path.join(config['depth_dir'], \"%04d\"%img_nr + ' 02.png')\n",
    "    image_rgb = cv2.cvtColor(cv2.imread(filename_rgb), cv2.COLOR_BGR2RGB)\n",
    "    image_depth = cv2.imread(filename_depth, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    inputs = {}\n",
    "    inputs['rgb'] = np.expand_dims(image_rgb, 0)\n",
    "    inputs['depth'] = np.expand_dims(np.expand_dims(image_depth, 0), -1)\n",
    "\n",
    "    resultsResnet = learnerResnet.inference(inputs, sessResnet)\n",
    "    pred_resnet = np.squeeze(resultsResnet['depth_prediction'])\n",
    "\n",
    "    a1 = fig.add_subplot(3,n_cols,fig_row)\n",
    "    a1.axis(\"off\")\n",
    "    a1.imshow(image_rgb, cmap='jet')\n",
    "    a2 = fig.add_subplot(3,n_cols,fig_row+1)\n",
    "    a2.axis(\"off\")\n",
    "    a2.imshow(image_depth, cmap='jet')\n",
    "    a3 = fig.add_subplot(3,n_cols,fig_row+2)\n",
    "    a3.axis(\"off\")\n",
    "    a3.imshow(pred_resnet, cmap='jet')\n",
    "    a1.set_title('RGB')\n",
    "    a2.set_title('Target')\n",
    "    a3.set_title('Ours')\n",
    "\n",
    "    if config['use_eigen']:\n",
    "        resultsEigen = learnerEigen.inference(inputs, sessEigen)\n",
    "        pred_eigen = np.squeeze(resultsEigen['depth_prediction'])\n",
    "        a4 = fig.add_subplot(3,4,fig_row+3)\n",
    "        a4.axis(\"off\")\n",
    "        a4.imshow(pred_eigen)\n",
    "        a4.set_title('Eigen et al.')\n",
    "    else:\n",
    "        fig_row+=n_cols\n",
    "\n",
    "fig.tight_layout()\n",
    "#out_path = '/home/rpg_students/moritz/figures/depth_predictions'\n",
    "#plt.savefig(os.path.join(out_path, config['ds']+'-DepthPredictions-'+ str(n)+'.png'), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Calculate performance metrics\n",
    "#---------------------#\n",
    "rmse_resnet = []\n",
    "rel_resnet = []\n",
    "simse_resnet = []\n",
    "logrmse_resnet = []\n",
    "d125_resnet = []\n",
    "\n",
    "rmse_eigen = []\n",
    "rel_eigen = []\n",
    "simse_eigen = []\n",
    "logrmse_eigen = []\n",
    "d125_eigen = []\n",
    "\n",
    "n_images = 4500\n",
    "sample_spacing = 100\n",
    "# Only even img_numbers are allowed\n",
    "for img_nr in range(2, 4500, sample_spacing):\n",
    "    filename_rgb = os.path.join(config['rgb_dir'], \"%04d\"%img_nr + ' 02.png')\n",
    "    filename_depth = os.path.join(config['depth_dir'], \"%04d\"%img_nr + ' 02.png')\n",
    "    image_rgb = cv2.cvtColor(cv2.imread(filename_rgb), cv2.COLOR_BGR2RGB)\n",
    "    image_depth = cv2.imread(filename_depth, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    inputs = {}\n",
    "    inputs['rgb'] = np.expand_dims(image_rgb, 0)\n",
    "    inputs['depth'] = np.expand_dims(np.expand_dims(image_depth, 0), -1)\n",
    "\n",
    "    resultsResnet = learnerResnet.inference(inputs, sessResnet)\n",
    "    pred_resnet = np.squeeze(resultsResnet['depth_prediction'])\n",
    "    \n",
    "    rmse_resnet.append(calc_rmse(pred_resnet, image_depth))\n",
    "    logrmse_resnet.append(calc_logrmse(pred_resnet, image_depth))\n",
    "    rel_resnet.append(calc_rel(pred_resnet, image_depth))\n",
    "    simse_resnet.append(calc_simse(pred_resnet, image_depth))\n",
    "    d125_resnet.append(calc_d125(pred_resnet, image_depth))\n",
    "    \n",
    "    if config['use_eigen']:\n",
    "        pred_eigen = np.squeeze(resultsEigen['depth_prediction'])\n",
    "        resultsEigen = learnerEigen.inference(inputs, sessEigen)\n",
    "\n",
    "        rmse_eigen.append(calc_rmse(pred_eigen, image_depth))\n",
    "        logrmse_eigen.append(calc_logrmse(pred_eigen, image_depth))\n",
    "        rel_eigen.append(calc_rel(pred_eigen, image_depth))\n",
    "        simse_eigen.append(calc_simse(pred_eigen, image_depth))\n",
    "        d125_eigen.append(calc_d125(pred_eigen, image_depth))\n",
    "\n",
    "# Average performance over all samples\n",
    "avg_rmse_resnet = np.mean(rmse_resnet)\n",
    "avg_rel_resnet = np.mean(rel_resnet)\n",
    "avg_simse_resnet = np.mean(simse_resnet)\n",
    "avg_logrmse_resnet = np.mean(logrmse_resnet)\n",
    "avg_d125_resnet = np.mean(d125_resnet)\n",
    "\n",
    "print(\"N samples: %d\" % len(rmse_resnet))\n",
    "if config['use_eigen']:\n",
    "    avg_rmse_eigen = np.mean(rmse_eigen)\n",
    "    avg_rel_eigen = np.mean(rel_eigen)\n",
    "    avg_simse_eigen = np.mean(simse_eigen)\n",
    "    avg_logrmse_eigen = np.mean(logrmse_eigen)\n",
    "    avg_d125_eigen = np.mean(d125_eigen)\n",
    "    print(\"Performance(Resnet/Eigen) - Rel: %f/%f, RMSE: %f/%f, logRMSE: %f/%f, SIMSE: %f/%f, D1.25: %f/%f\" \n",
    "      % (avg_rel_resnet, avg_rel_eigen, avg_rmse_resnet, avg_rmse_eigen, avg_logrmse_resnet, avg_logrmse_eigen, \n",
    "         avg_simse_resnet, avg_simse_eigen, avg_d125_resnet, avg_d125_eigen))\n",
    "else:\n",
    "    print(\"Performance(Resnet) - Rel: %f, RMSE: %f, logRMSE: %f, SIMSE: %f, D1.25: %f\" \n",
    "      % (avg_rel_resnet, avg_rmse_resnet, avg_logrmse_resnet, avg_simse_resnet, avg_d125_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "# Plot performance history over test split\n",
    "#---------------------#\n",
    "fig = plt.figure()\n",
    "a1 = fig.add_subplot(2,3,1)\n",
    "a1.set_title('Rel error')\n",
    "a1.plot(rel_resnet)\n",
    "a2 = fig.add_subplot(2,3,2)\n",
    "a2.set_title('RMSE')\n",
    "a2.plot(rmse_resnet)\n",
    "a3 = fig.add_subplot(2,3,3)\n",
    "a3.set_title('logRMSE')\n",
    "a3.plot(logrmse_resnet)\n",
    "a4 = fig.add_subplot(2,3,4)\n",
    "a4.set_title('SI MSE')\n",
    "a4.plot(simse_resnet)\n",
    "a5 = fig.add_subplot(2,3,5)\n",
    "a5.set_title('D1.25')\n",
    "a5.plot(d125_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
